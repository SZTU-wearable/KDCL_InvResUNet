{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T10:34:43.215668088Z",
     "start_time": "2023-08-17T10:34:42.278742912Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "# from Teacher import Teacher_Model\n",
    "from Teacher import Teacher_Model\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import os\n",
    "# from Utils_tool import EarlyStopping\n",
    "# from Utils_tool_1 import load_data_drink\n",
    "# from Utils_tool_1 import load_data_exercise\n",
    "# from Utils_tool_1 import load_data_mimic_ii\n",
    "import sys\n",
    "# from transformers import AdamW\n",
    "import torch.optim as optim\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T10:34:44.894139595Z",
     "start_time": "2023-08-17T10:34:43.214994004Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T10:34:44.921933429Z",
     "start_time": "2023-08-17T10:34:44.895768109Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return torch.Tensor(np.array(self.x_data[index])), torch.Tensor(\n",
    "            np.array(self.y_data[index]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T10:34:44.945992143Z",
     "start_time": "2023-08-17T10:34:44.906635901Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "def visualization(y1):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(y=y1,\n",
    "                   mode=\"lines\",\n",
    "                   line=dict(color=\"blue\"),\n",
    "                   name=\"predict value\"))\n",
    "    fig.update_layout()\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T10:34:44.973437883Z",
     "start_time": "2023-08-17T10:34:44.919422752Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "\n",
    "def load_data_pulseDB(idx):\n",
    "    x_tol_arr = []\n",
    "    y_tol_arr = []\n",
    "    for i in range(1, 11):\n",
    "        # file_name = '/home/yonghu/data_yonghu/code_python/PulseDB_Ten_0728/Group%02d_in_out_split.h5' % i\n",
    "        file_name = '/home/yonghu/data_yonghu/code_python/VitalDB_dataset/VitalDB_Ten_0927/Group%02d_in_out_split.h5' % i\n",
    "        print(file_name)\n",
    "        with h5py.File(file_name, \"r\") as file:\n",
    "            for dataset_name in file:\n",
    "                if dataset_name == 'In_Signals':\n",
    "                    In_Signals = file[dataset_name][()][:, :, ::2]\n",
    "                    print(In_Signals.shape)\n",
    "                    x_tol_arr.append(In_Signals)\n",
    "                elif dataset_name == 'Out_Signals':\n",
    "                    Out_Signals = file[dataset_name][()][:, :, ::2]\n",
    "                    print(Out_Signals.shape)\n",
    "                    y_tol_arr.append(Out_Signals)\n",
    "\n",
    "    x_train_load_data = x_tol_arr[3:10] + x_tol_arr[0:1]\n",
    "    x_val_load_data = x_tol_arr[2:3]\n",
    "    x_test_load_data = x_tol_arr[1:2]\n",
    "    x_train_load_data = np.vstack(x_train_load_data)\n",
    "    x_val_load_data = np.vstack(x_val_load_data)\n",
    "    x_test_load_data = np.vstack(x_test_load_data)\n",
    "    print(x_train_load_data.shape)\n",
    "    print(x_val_load_data.shape)\n",
    "    print(x_test_load_data.shape)\n",
    "    y_train_load_data = y_tol_arr[3:10] + y_tol_arr[0:1]\n",
    "    y_val_load_data = y_tol_arr[2:3]\n",
    "    y_test_load_data = y_tol_arr[1:2]\n",
    "    y_train_load_data = np.vstack(y_train_load_data)\n",
    "    y_val_load_data = np.vstack(y_val_load_data)\n",
    "    y_test_load_data = np.vstack(y_test_load_data)\n",
    "    print(y_train_load_data.shape)\n",
    "    print(y_val_load_data.shape)\n",
    "    print(y_test_load_data.shape)\n",
    "\n",
    "    # y_test_load_data = y_test_load_data / 300\n",
    "\n",
    "    # x_train_load_data = x_train_load_data[0:1000]\n",
    "    # y_train_load_data = y_train_load_data[0:1000]\n",
    "    # x_val_load_data = x_val_load_data[0:1000]\n",
    "    # y_val_load_data = y_val_load_data[0:1000]\n",
    "    # x_test_load_data = x_test_load_data[0:1000]\n",
    "    # y_test_load_data = y_test_load_data[0:1000]\n",
    "\n",
    "    x_train_data = torch.tensor(x_train_load_data)\n",
    "    y_train_data = torch.tensor(y_train_load_data)\n",
    "    x_val_data = torch.tensor(x_val_load_data)\n",
    "    y_val_data = torch.tensor(y_val_load_data)\n",
    "    x_test_data = torch.tensor(x_test_load_data)\n",
    "    y_test_data = torch.tensor(y_test_load_data)\n",
    "\n",
    "    train_data_set = MyDataset(x_train_data, y_train_data)\n",
    "    val_data_set = MyDataset(x_val_data, y_val_data)\n",
    "    test_data_set = MyDataset(x_test_data, y_test_data)\n",
    "\n",
    "    return train_data_set, val_data_set, test_data_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T10:35:41.944564521Z",
     "start_time": "2023-08-17T10:34:44.962126791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yonghu/data_yonghu/code_python/VitalDB_dataset/VitalDB_Ten_0927/Group01_in_out_split.h5\n",
      "(125730, 4, 625)\n",
      "(125730, 1, 625)\n",
      "/home/yonghu/data_yonghu/code_python/VitalDB_dataset/VitalDB_Ten_0927/Group02_in_out_split.h5\n",
      "(125779, 4, 625)\n",
      "(125779, 1, 625)\n",
      "/home/yonghu/data_yonghu/code_python/VitalDB_dataset/VitalDB_Ten_0927/Group03_in_out_split.h5\n",
      "(125779, 4, 625)\n",
      "(125779, 1, 625)\n",
      "/home/yonghu/data_yonghu/code_python/VitalDB_dataset/VitalDB_Ten_0927/Group04_in_out_split.h5\n",
      "(125779, 4, 625)\n",
      "(125779, 1, 625)\n",
      "/home/yonghu/data_yonghu/code_python/VitalDB_dataset/VitalDB_Ten_0927/Group05_in_out_split.h5\n",
      "(125659, 4, 625)\n",
      "(125659, 1, 625)\n",
      "/home/yonghu/data_yonghu/code_python/VitalDB_dataset/VitalDB_Ten_0927/Group06_in_out_split.h5\n",
      "(125659, 4, 625)\n",
      "(125659, 1, 625)\n",
      "/home/yonghu/data_yonghu/code_python/VitalDB_dataset/VitalDB_Ten_0927/Group07_in_out_split.h5\n",
      "(125659, 4, 625)\n",
      "(125659, 1, 625)\n",
      "/home/yonghu/data_yonghu/code_python/VitalDB_dataset/VitalDB_Ten_0927/Group08_in_out_split.h5\n",
      "(125659, 4, 625)\n",
      "(125659, 1, 625)\n",
      "/home/yonghu/data_yonghu/code_python/VitalDB_dataset/VitalDB_Ten_0927/Group09_in_out_split.h5\n",
      "(125659, 4, 625)\n",
      "(125659, 1, 625)\n",
      "/home/yonghu/data_yonghu/code_python/VitalDB_dataset/VitalDB_Ten_0927/Group10_in_out_split.h5\n",
      "(125779, 4, 625)\n",
      "(125779, 1, 625)\n",
      "(1005583, 4, 625)\n",
      "(125779, 4, 625)\n",
      "(125779, 4, 625)\n",
      "(1005583, 1, 625)\n",
      "(125779, 1, 625)\n",
      "(125779, 1, 625)\n",
      "Folder 'VitalDB_DataLoader_tol/Folder02/' created.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data_set, val_data_set, test_data_set = load_data_pulseDB(\"01\")\n",
    "import os\n",
    "def create_folder_if_not_exists(folder_path):\n",
    "    # 使用 os.path.exists() 判断文件夹是否存在\n",
    "    if not os.path.exists(folder_path):\n",
    "        # 如果文件夹不存在，则创建新的文件夹\n",
    "        os.mkdir(folder_path)\n",
    "        print(f\"Folder '{folder_path}' created.\\n\")\n",
    "    else:\n",
    "        print(f\"Folder '{folder_path}' already exists.\\n\")\n",
    "        \n",
    "dir_name = \"VitalDB_DataLoader_tol/Folder02/\"\n",
    "create_folder_if_not_exists(dir_name)\n",
    "torch.save(train_data_set, dir_name+\"train_dataset.pt\")\n",
    "torch.save(val_data_set, dir_name+\"val_dataset.pt\")\n",
    "torch.save(test_data_set, dir_name+\"test_dataset.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T10:35:41.961595907Z",
     "start_time": "2023-08-17T10:35:41.947634511Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data_set, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data_set, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_data_set, batch_size=64, shuffle=False)\n",
    "print(len(train_loader), len(val_loader), len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T10:35:41.961879477Z",
     "start_time": "2023-08-17T10:35:41.950132719Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer, criterion=nn.L1Loss(), num_epochs=100, patience=7,\n",
    "                save_path=None):\n",
    "    best_val_loss = float('inf')\n",
    "    no_improvement = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        for id, (inputs, targets) in enumerate(train_loader_tqdm):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            train_loader_tqdm.set_postfix(loss=f\"{total_loss / (id + 1):.4f}\")\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        total_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = total_loss / len(val_loader)\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {avg_train_loss:.6f}, Validation Loss: {avg_val_loss:.6f}, Best Loss: {best_val_loss:.6f}\")\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            print(\n",
    "                f'Validation loss decreased ({best_val_loss:.6f} --> {avg_val_loss:.6f}).  Saving model ...'\n",
    "            )\n",
    "            best_val_loss = avg_val_loss\n",
    "            no_improvement = 0\n",
    "\n",
    "            if save_path is not None:\n",
    "                current_datetime = datetime.now()\n",
    "                current_datetime_str = current_datetime.strftime('_%Y_%m_%d_%H:%M:%S')\n",
    "                path_name = save_path + current_datetime_str + \".pth\"\n",
    "                torch.save(model.state_dict(), path_name)\n",
    "                best_model = model\n",
    "                print(f\"Saved the best model to '{path_name}'.\")\n",
    "            else:\n",
    "                print(\"Not Save!!!!\")\n",
    "\n",
    "        else:\n",
    "            no_improvement += 1\n",
    "            print(\n",
    "                f'EarlyStopping counter: {no_improvement} out of {patience}'\n",
    "            )\n",
    "\n",
    "        if no_improvement >= patience:\n",
    "            print(\"Early Stopping! Training stopped.\")\n",
    "            break\n",
    "\n",
    "    print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T10:35:42.008716909Z",
     "start_time": "2023-08-17T10:35:41.963520158Z"
    }
   },
   "outputs": [],
   "source": [
    "# 测试模型\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    criterion = nn.L1Loss()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    print(f\"Test Loss: {total_loss / len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-19T06:48:20.565639412Z",
     "start_time": "2023-08-17T10:35:41.971300964Z"
    }
   },
   "outputs": [],
   "source": [
    "weight_path = \"weight_model/UtransBPNet_VitalDB_Fold02_\"\n",
    "model = Teacher_Model(4, 128, 7, 3).to(device)\n",
    "\n",
    "loss_fun = nn.L1Loss()\n",
    "# opt = optim.Adam(model.parameters(), lr=1e-3)\n",
    "opt = optim.AdamW(model.parameters(), lr=1e-5, weight_decay=0.1)\n",
    "\n",
    "\n",
    "best_model = \"\"\n",
    "\n",
    "train_model(model, train_loader=train_loader, val_loader=val_loader, optimizer=opt, criterion=loss_fun, num_epochs=100,\n",
    "            patience=10, save_path=weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-19T07:00:23.645610063Z",
     "start_time": "2023-08-19T06:48:20.565366180Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_model(model=best_model.to(device), test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-19T07:00:23.646139032Z",
     "start_time": "2023-08-19T07:00:23.645429552Z"
    }
   },
   "outputs": [],
   "source": [
    "# # 测试\n",
    "# import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "# def visualization(y1, y2, mae):\n",
    "#     ME = np.mean(y1 - y2)\n",
    "#     SD = np.std(y1 - y2)\n",
    "#     fig = go.Figure()\n",
    "\n",
    "#     fig.add_trace(\n",
    "#         go.Scatter(y=y1[0:12500],\n",
    "#                    mode=\"lines\",\n",
    "#                    line=dict(color=\"blue\"),\n",
    "#                    name=\"predict value\"))\n",
    "#     fig.add_trace(\n",
    "#         go.Scatter(y=y2[0:12500],\n",
    "#                    mode=\"lines\",\n",
    "#                    line=dict(color=\"red\"),\n",
    "#                    name=\"actual value\"))\n",
    "\n",
    "#     tit_name = \"mae = \" + str(mae) + \"      \" + \\\n",
    "#                \"me = \" + str(ME) + \"     \" + \"SD = \" + str(SD)\n",
    "#     fig.update_layout(title=tit_name)\n",
    "#     fig.show()\n",
    "\n",
    "# # visualization(ture_data, pred_data, mae_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-19T07:00:23.646651859Z",
     "start_time": "2023-08-19T07:00:23.645917202Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = Teacher_Model(4, 128, 7, 3)\n",
    "# model.load_state_dict(torch.load(weight_path))\n",
    "\n",
    "# y_true = np.array([])\n",
    "# out = np.array([])\n",
    "# with torch.no_grad():\n",
    "#     model.eval()\n",
    "#     for z, (x, y) in enumerate((test_loader)):\n",
    "#         input_data = x\n",
    "#         y = y\n",
    "#         temp = model(input_data)\n",
    "#         out = np.append(out, temp.detach().cpu().numpy().flatten())\n",
    "#         y_true = np.append(y_true, y.detach().cpu().numpy().flatten())\n",
    "\n",
    "#     out = out\n",
    "#     y_true = y_true\n",
    "#     mae = np.mean(np.abs(out - y_true))\n",
    "#     print(\"MAE = \", mae)\n",
    "\n",
    "# visualization(y_true, out, mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kd_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8abdbce19a04336dc8c9a7c3108a4b754af3387b75c437a9a59216360a3587f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
