{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "/home/yonghu/data_yonghu/code_python/VitalDB_dataset/VitalDB_Ten_0927/Group01_in_out_split.h5\n",
      "(125730, 4, 625)\n",
      "(125730, 1, 625)\n",
      "/home/yonghu/data_yonghu/code_python/VitalDB_dataset/VitalDB_Ten_0927/Group02_in_out_split.h5\n",
      "(125779, 4, 625)\n",
      "(125779, 1, 625)\n",
      "/home/yonghu/data_yonghu/code_python/VitalDB_dataset/VitalDB_Ten_0927/Group03_in_out_split.h5\n",
      "(125779, 4, 625)\n",
      "(125779, 1, 625)\n",
      "/home/yonghu/data_yonghu/code_python/VitalDB_dataset/VitalDB_Ten_0927/Group04_in_out_split.h5\n",
      "(125779, 4, 625)\n",
      "(125779, 1, 625)\n",
      "/home/yonghu/data_yonghu/code_python/VitalDB_dataset/VitalDB_Ten_0927/Group05_in_out_split.h5\n",
      "(125659, 4, 625)\n",
      "(125659, 1, 625)\n",
      "/home/yonghu/data_yonghu/code_python/VitalDB_dataset/VitalDB_Ten_0927/Group06_in_out_split.h5\n",
      "(125659, 4, 625)\n",
      "(125659, 1, 625)\n",
      "/home/yonghu/data_yonghu/code_python/VitalDB_dataset/VitalDB_Ten_0927/Group07_in_out_split.h5\n",
      "(125659, 4, 625)\n",
      "(125659, 1, 625)\n",
      "/home/yonghu/data_yonghu/code_python/VitalDB_dataset/VitalDB_Ten_0927/Group08_in_out_split.h5\n",
      "(125659, 4, 625)\n",
      "(125659, 1, 625)\n",
      "/home/yonghu/data_yonghu/code_python/VitalDB_dataset/VitalDB_Ten_0927/Group09_in_out_split.h5\n",
      "(125659, 4, 625)\n",
      "(125659, 1, 625)\n",
      "/home/yonghu/data_yonghu/code_python/VitalDB_dataset/VitalDB_Ten_0927/Group10_in_out_split.h5\n",
      "(125779, 4, 625)\n",
      "(125779, 1, 625)\n",
      "(1005583, 4, 625)\n",
      "(125779, 4, 625)\n",
      "(125779, 4, 625)\n",
      "(1005583, 1, 625)\n",
      "(125779, 1, 625)\n",
      "(125779, 1, 625)\n",
      "Folder 'VitalDB_DataLoader_tol/Folder03/' created.\n",
      "\n",
      "15713 1966 1966\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "# from Teacher import Teacher_Model\n",
    "from Teacher import Teacher_Model\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import os\n",
    "# from Utils_tool import EarlyStopping\n",
    "# from Utils_tool_1 import load_data_drink\n",
    "# from Utils_tool_1 import load_data_exercise\n",
    "# from Utils_tool_1 import load_data_mimic_ii\n",
    "import sys\n",
    "# from transformers import AdamW\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return torch.Tensor(np.array(self.x_data[index])), torch.Tensor(\n",
    "            np.array(self.y_data[index]))\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "def visualization(y1):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(y=y1,\n",
    "                   mode=\"lines\",\n",
    "                   line=dict(color=\"blue\"),\n",
    "                   name=\"predict value\"))\n",
    "    fig.update_layout()\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def load_data_pulseDB(idx):\n",
    "    x_tol_arr = []\n",
    "    y_tol_arr = []\n",
    "    for i in range(1, 11):\n",
    "        # file_name = '/home/yonghu/data_yonghu/code_python/PulseDB_Ten_0728/Group%02d_in_out_split.h5' % i\n",
    "        file_name = '/home/yonghu/data_yonghu/code_python/VitalDB_dataset/VitalDB_Ten_0927/Group%02d_in_out_split.h5' % i\n",
    "        print(file_name)\n",
    "        with h5py.File(file_name, \"r\") as file:\n",
    "            for dataset_name in file:\n",
    "                if dataset_name=='In_Signals':\n",
    "                    In_Signals = file[dataset_name][()][:,:,::2]\n",
    "                    print(In_Signals.shape)\n",
    "                    x_tol_arr.append(In_Signals)\n",
    "                elif dataset_name=='Out_Signals':\n",
    "                    Out_Signals = file[dataset_name][()][:,:,::2]\n",
    "                    print(Out_Signals.shape)\n",
    "                    y_tol_arr.append(Out_Signals)\n",
    "            \n",
    "    x_train_load_data = x_tol_arr[4:10] + x_tol_arr[0:2]\n",
    "    x_val_load_data = x_tol_arr[3:4]\n",
    "    x_test_load_data = x_tol_arr[2:3]\n",
    "    x_train_load_data = np.vstack(x_train_load_data)\n",
    "    x_val_load_data = np.vstack(x_val_load_data)\n",
    "    x_test_load_data = np.vstack(x_test_load_data)\n",
    "    print(x_train_load_data.shape)\n",
    "    print(x_val_load_data.shape)\n",
    "    print(x_test_load_data.shape)\n",
    "    y_train_load_data = y_tol_arr[4:10] + y_tol_arr[0:2]\n",
    "    y_val_load_data = y_tol_arr[3:4]\n",
    "    y_test_load_data = y_tol_arr[2:3]\n",
    "    y_train_load_data = np.vstack(y_train_load_data)\n",
    "    y_val_load_data = np.vstack(y_val_load_data)\n",
    "    y_test_load_data = np.vstack(y_test_load_data)\n",
    "    print(y_train_load_data.shape)\n",
    "    print(y_val_load_data.shape)\n",
    "    print(y_test_load_data.shape)\n",
    "\n",
    "    # y_test_load_data = y_test_load_data / 300\n",
    "\n",
    "    # x_train_load_data = x_train_load_data[0:1000]\n",
    "    # y_train_load_data = y_train_load_data[0:1000]\n",
    "    # x_val_load_data = x_val_load_data[0:1000]\n",
    "    # y_val_load_data = y_val_load_data[0:1000]\n",
    "    # x_test_load_data = x_test_load_data[0:1000]\n",
    "    # y_test_load_data = y_test_load_data[0:1000]\n",
    "\n",
    "    x_train_data = torch.tensor(x_train_load_data)\n",
    "    y_train_data = torch.tensor(y_train_load_data)\n",
    "    x_val_data = torch.tensor(x_val_load_data)\n",
    "    y_val_data = torch.tensor(y_val_load_data)\n",
    "    x_test_data = torch.tensor(x_test_load_data)\n",
    "    y_test_data = torch.tensor(y_test_load_data)\n",
    "\n",
    "    train_data_set = MyDataset(x_train_data, y_train_data)\n",
    "    val_data_set = MyDataset(x_val_data, y_val_data)\n",
    "    test_data_set = MyDataset(x_test_data, y_test_data)\n",
    "\n",
    "    return train_data_set, val_data_set, test_data_set\n",
    "\n",
    "train_data_set, val_data_set, test_data_set = load_data_pulseDB(\"01\")\n",
    "import os\n",
    "def create_folder_if_not_exists(folder_path):\n",
    "    # 使用 os.path.exists() 判断文件夹是否存在\n",
    "    if not os.path.exists(folder_path):\n",
    "        # 如果文件夹不存在，则创建新的文件夹\n",
    "        os.mkdir(folder_path)\n",
    "        print(f\"Folder '{folder_path}' created.\\n\")\n",
    "    else:\n",
    "        print(f\"Folder '{folder_path}' already exists.\\n\")\n",
    "        \n",
    "dir_name = \"VitalDB_DataLoader_tol/Folder03/\"\n",
    "create_folder_if_not_exists(dir_name)\n",
    "torch.save(train_data_set, dir_name+\"train_dataset.pt\")\n",
    "torch.save(val_data_set, dir_name+\"val_dataset.pt\")\n",
    "torch.save(test_data_set, dir_name+\"test_dataset.pt\")\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_data_set, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data_set, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_data_set, batch_size=64, shuffle=False)\n",
    "print(len(train_loader), len(val_loader), len(test_loader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "st_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
