{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "# from InvertedResidual_small_Unet import invertedResidual_unet\n",
    "sys.path.append('../Model')\n",
    "from InvertedResidual_large_Unet import invertedResidual_unet\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import argparse\n",
    "import h5py\n",
    "from scipy.io import savemat\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return torch.Tensor(np.array(self.x_data[index])), torch.Tensor(\n",
    "            np.array(self.y_data[index]))\n",
    "\n",
    "def create_folder_if_not_exists(folder_path):\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "        print(f\"Folder created: {folder_path}\")\n",
    "    else:\n",
    "        print(f\"Folder already exists: {folder_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "tol_li = []\n",
    "for i in range(1,11):\n",
    "    directory = 'weight_model_4_utrans_unet_InSmUNet/InvertedResidual_UNet_large/'\n",
    "    pattern = 'InvertedResidual_UNet_largeFold%02d*' % i  \n",
    "    file_list = glob.glob(os.path.join(directory, pattern))\n",
    "    if not file_list:\n",
    "        print(\"no\\n\")\n",
    "    file_list.sort()\n",
    "    last_file = file_list[-1]\n",
    "    tol_li.append(last_file)\n",
    "tol_li\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024\n",
    "tol_abp_true = []\n",
    "tol_abp_pred = []\n",
    "weight_ten = tol_li\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold_number in range(1,11):\n",
    "    print(\"fold_number = \", fold_number)\n",
    "    dataset_dir_path = '/home/yonghu/data_yonghu/code_python/VitalDB_DataLoader_tol/Folder%02d/' % fold_number\n",
    "    weight_path = weight_ten[fold_number - 1]\n",
    "    test_data_set = torch.load(dataset_dir_path+\"test_dataset.pt\")\n",
    "    print(len(test_data_set))\n",
    "    test_loader = DataLoader(test_data_set, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    print(len(test_loader))\n",
    "    \n",
    "    model = invertedResidual_unet().to(device)\n",
    "    checkpoint = torch.load(weight_path)\n",
    "\n",
    "    model_state_dict = checkpoint['model'] if 'model' in checkpoint else checkpoint\n",
    "    # model_list[1].load_state_dict(torch.load(Teacher_Path))\n",
    "    model.load_state_dict(model_state_dict, strict=False)\n",
    "    \n",
    "    model.eval()\n",
    "    true_data = []\n",
    "    pred_data = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            true_data.append(targets.detach().cpu().numpy().flatten())\n",
    "            pred_data.append(outputs.detach().cpu().numpy().flatten())\n",
    "    true_data = np.concatenate(true_data)\n",
    "    pred_data = np.concatenate(pred_data)\n",
    "    tol_abp_true.append(true_data)\n",
    "    tol_abp_pred.append(pred_data)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol_abp_true_np = np.concatenate(tol_abp_true)\n",
    "tol_abp_pred_np = np.concatenate(tol_abp_pred)\n",
    "print(tol_abp_true_np.shape)\n",
    "print(tol_abp_pred_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = np.mean(np.abs(tol_abp_pred_np - tol_abp_true_np))\n",
    "errors = tol_abp_pred_np - tol_abp_true_np\n",
    "std = np.std(errors)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Standard Deviation (STD): {std}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "st_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
